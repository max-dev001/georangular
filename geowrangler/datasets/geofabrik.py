# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/05_datasets_geofabrik.ipynb (unless otherwise specified).

__all__ = [
    "list_geofabrik_regions",
    "download_geofabrik_region",
    "get_osm_download_url",
    "download_osm_country_data",
    "OsmDataManager",
]


# Internal Cell
import os
import shutil
import uuid
from functools import lru_cache
from pathlib import Path
from typing import Union
from urllib.parse import urlparse
from urllib.request import HTTPError
from zipfile import ZipFile

import geopandas as gpd
import requests
from fastcore.all import urlcheck
from loguru import logger

from geowrangler import distance_zonal_stats as dzs
from geowrangler import vector_zonal_stats as vzs
from .utils import make_report_hook, urlretrieve

# Internal Cell
DEFAULT_CACHE_DIR = "~/.geowrangler"

# Internal Cell
@lru_cache(maxsize=None)
def load_geofabrik_data():
    return requests.get("https://download.geofabrik.de/index-v1-nogeom.json").json()


# Cell
def list_geofabrik_regions() -> dict:
    """Get list of regions from geofabrik index"""
    geofabrik_data = load_geofabrik_data()
    return {
        k["properties"]["id"]: k["properties"]["urls"].get("shp")
        for k in geofabrik_data["features"]
        if k["properties"]["urls"].get("shp")
    }


# Cell
def download_geofabrik_region(
    region: str,
    directory: str = "data/",
    overwrite=False,
    year=None,
    show_progress=True,
    chunksize=8192,
) -> Union[Path, None]:
    """Download geofabrik region to path"""
    if not os.path.isdir(directory):
        os.makedirs(directory)
    geofabrik_info = list_geofabrik_regions()
    if region not in geofabrik_info:
        raise ValueError(
            f"{region} not found in geofabrik. Run list_geofabrik_regions() to learn more about available areas"
        )
    url = geofabrik_info[region]
    if year is not None:
        short_year = str(year)[-2:]  # take last 2 digits
        year_prefix = f"{short_year}0101"
        url = url.replace("latest", year_prefix)

    parsed_url = urlparse(url)
    filename = Path(os.path.basename(parsed_url.path))
    filepath = directory / filename
    if not filepath.exists() or overwrite:
        reporthook = make_report_hook(show_progress)

        try:
            filepath, _, _ = urlretrieve(
                url, filepath, reporthook=reporthook, chunksize=chunksize
            )
        except HTTPError as err:
            if err.code == 404:
                if year is not None:
                    logger.warning(
                        f"No data found for year {year} in region {region} : {url}"
                    )
                else:
                    logger.warning(f"No url found for region {region} : {url} ")
                return None
            else:
                raise err

    return filepath


# Cell
def get_osm_download_url(region, year=None):
    geofabrik_info = list_geofabrik_regions()
    if region not in geofabrik_info:
        raise ValueError(
            f"{region} not found in geofabrik. Run list_geofabrik_regions() to learn more about available areas"
        )
    url = geofabrik_info[region]
    if year is not None:
        short_year = str(year)[-2:]  # take last 2 digits
        year_prefix = f"{short_year}0101"
        url = url.replace("latest", year_prefix)
    return url


# Cell


def download_osm_country_data(
    country,
    year=None,
    cache_dir=DEFAULT_CACHE_DIR,
    use_cache=True,
    chunksize=8192,
    show_progress=True,
):

    osm_cache_dir = os.path.join(os.path.expanduser(cache_dir), "osm/")
    # TODO consider incorporating year or quarter to automatically avoid using stale data

    # Check if the cached data is valid. Otherwise, we have to re-download.
    # Temporary quick check now is to see if the country cache folder is non-empty.
    # TODO: Can improve this later if we need more specific validity checks.
    if year is None:
        country_cache_dir = os.path.join(osm_cache_dir, country)
        cached_data_available = (
            os.path.exists(country_cache_dir) and len(os.listdir(country_cache_dir)) > 0
        )
    else:
        short_year = str(year)[-2:]  # take last 2 digits
        year_prefix = f"{short_year}0101"
        lookup = f"{country}-{year_prefix}"
        country_cache_dir = os.path.join(osm_cache_dir, lookup)
        cached_data_available = (
            os.path.exists(country_cache_dir) and len(os.listdir(country_cache_dir)) > 0
        )

    logger.info(
        f"OSM Data: Cached data available for {country} at {country_cache_dir}? {cached_data_available}"
    )

    # Download if cache is invalid or user specified use_cache = False
    if not cached_data_available or not use_cache:
        url = get_osm_download_url(country, year=year)
        if not urlcheck(url):
            if year is None:
                logger.warning(f"OSM data for {country} is not available")
            else:
                logger.warning(
                    f"OSM data for {country} and year {year} is not available"
                )
            return None

        logger.info(
            f"OSM Data: Re-initializing OSM country cache dir at {country_cache_dir}..."
        )
        # Re-create the country cache dir and start over to fix any corrupted states
        shutil.rmtree(country_cache_dir, ignore_errors=True)
        Path(country_cache_dir).mkdir(parents=True, exist_ok=True)

        # This downloads a zip file to the country cache dir
        logger.info(f"OSM Data: Downloading Geofabrik in {country_cache_dir}...")
        zipfile_path = download_geofabrik_region(
            country,
            year=year,
            directory=country_cache_dir,
            show_progress=show_progress,
            chunksize=chunksize,
        )
        if zipfile_path is None:
            return None
        # Unzip the zip file
        logger.info(f"OSM Data: Unzipping the zip file {zipfile_path}...")
        with ZipFile(zipfile_path, "r") as zip_object:
            zip_object.extractall(country_cache_dir)

        # Delete the zip file
        os.remove(zipfile_path)
        if year is None:
            logger.info(
                f"OSM Data: Successfully downloaded and cached OSM data for {country} at {country_cache_dir}!"
            )
        else:
            logger.info(
                f"OSM Data: Successfully downloaded and cached OSM data for {country} and {year} at {country_cache_dir}!"
            )

    return country_cache_dir


# Cell


class OsmDataManager:
    """An instance of this class provides convenience functions for loading and caching OSM data"""

    def __init__(self, cache_dir=DEFAULT_CACHE_DIR):
        self.cache_dir = os.path.expanduser(cache_dir)
        self.pois_cache = {}
        self.roads_cache = {}

    def load_pois(
        self,
        country,
        year=None,
        use_cache=True,
        chunksize=1024 * 1024,
        show_progress=True,
    ):
        # Get from RAM cache if already available
        if year is None:
            if country in self.pois_cache:
                logger.debug(f"OSM POIs for {country} found in cache.")
                return self.pois_cache[country]
        else:
            short_year = str(year)[-2:]
            lookup = f"{country}_{short_year}"
            if lookup in self.pois_cache:
                logger.debug(f"OSM POIs for {country} and year {year} found in cache.")
                return self.pois_cache[lookup]

        # Otherwise, load from file and add to cache
        country_cache_dir = download_osm_country_data(
            country,
            year=year,
            cache_dir=self.cache_dir,
            use_cache=use_cache,
            chunksize=chunksize,
            show_progress=show_progress,
        )
        if country_cache_dir is None:
            return None

        osm_pois_filepath = os.path.join(country_cache_dir, "gis_osm_pois_free_1.shp")
        if year is None:
            logger.debug(
                f"OSM POIs for {country} being loaded from {osm_pois_filepath}"
            )
        else:
            logger.debug(
                f"OSM POIs for {country} and year {year} being loaded from {osm_pois_filepath}"
            )
        gdf = gpd.read_file(osm_pois_filepath)

        if year is None:
            self.pois_cache[country] = gdf
        else:
            short_year = str(year)[-2:]
            lookup = f"{country}_{short_year}"
            self.pois_cache[lookup] = gdf

        return gdf

    def load_roads(
        self,
        country,
        year=None,
        use_cache=True,
        chunksize=1024 * 1024,
        show_progress=True,
    ):
        # Get from RAM cache if already available
        if year is None:
            if country in self.roads_cache:
                logger.debug(f"OSM POIs for {country} found in cache.")
                return self.roads_cache[country]
        else:
            short_year = str(year)[-2:]
            lookup = f"{country}_{short_year}"
            if lookup in self.roads_cache:
                logger.debug(f"OSM POIs for {country} and year {year} found in cache.")
                return self.roads_cache[lookup]

        # Otherwise, load from file and add to cache
        country_cache_dir = download_osm_country_data(
            country,
            year=year,
            cache_dir=self.cache_dir,
            use_cache=use_cache,
            chunksize=chunksize,
            show_progress=show_progress,
        )

        if country_cache_dir is None:
            return None

        osm_roads_filepath = os.path.join(country_cache_dir, "gis_osm_roads_free_1.shp")
        if year is None:
            logger.debug(
                f"OSM Roads for {country} being loaded from {osm_roads_filepath}"
            )
        else:
            logger.debug(
                f"OSM Roads for {country} and year {year} being loaded from {osm_roads_filepath}"
            )
        gdf = gpd.read_file(osm_roads_filepath)

        if year is None:
            self.roads_cache[country] = gdf
        else:
            short_year = str(year)[-2:]
            lookup = f"{country}_{short_year}"
            self.roads_cache[lookup] = gdf

        return gdf
